{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0c795aebd7ac18c150a626b1239630d4a359de6700ed411c36eca50a9cfe8623c",
   "display_name": "Python 3.7.7 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/Users/adityanaik/anaconda3/lib/python3.7/site-packages/dask/config.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/Users/adityanaik/anaconda3/lib/python3.7/site-packages/dask/dataframe/utils.py:13: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n",
      "/Users/adityanaik/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import datetime\n",
    "import pytz\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Model dev\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import pickle\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "source": [
    "**Section 1: Data Cleaning**\n",
    "\n",
    "Like with any model development process, we will begin by sifting through our dataset and extracting only the required features."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_df = pd.read_csv(\"./mlb_elo.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_df = elo_df.loc[elo_df['season'] >= 2000]\n",
    "elo_df = elo_df.loc[elo_df['season'] <= 2020]\n",
    "# elo_df = elo_df[~elo_df['pitcher1'].str.contains(r'[0-9]')]\n",
    "# elo_df = elo_df[~elo_df['pitcher2'].str.contains(r'[0-9]')]\n",
    "\n",
    "elo_df['date']= pd.to_datetime(elo_df['date'])\n",
    "\n",
    "elo_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo_df.to_csv( \"elo_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elo1_pre = 1531.8233671069\n",
    "elo2_pre = 1456.6148797361\n",
    "elo1_post = 1529.9288796768\n",
    "elo2_post = 1458.5093671663\n",
    "\n",
    "trans_rating1 = 10**(elo1_pre / 400.0)\n",
    "trans_rating2 = 10**(elo2_pre / 400.0)\n",
    "\n",
    "exp_score1 = elo1_pre / (elo1_pre + elo2_pre)\n",
    "exp_score2 = elo2_pre / (elo1_pre + elo2_pre)\n",
    "\n",
    "win_loss1 = 0\n",
    "win_loss2 = 1\n",
    "\n",
    "# calculate k\n",
    "k1 = (elo1_post - elo1_pre) / (win_loss1 - exp_score1)\n",
    "k2 = (elo2_post - elo2_pre) / (win_loss2 - exp_score2)\n",
    "\n",
    "print(\"K1: \" + str(k1))\n",
    "print(\"K2: \" + str(k2))\n",
    "\n",
    "# 4.64\n",
    "# 4.60\n",
    "# 5.10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo_k(point_diff, elo_diff):\n",
    "    k = 32\n",
    "\n",
    "    if point_diff>0:\n",
    "        multiplier=(point_diff)**(0.5)/(10+0.01*(elo_diff))\n",
    "    else:\n",
    "        multiplier=(-point_diff)**(0.5)/(10+0.01*(-elo_diff))\n",
    "    return k*multiplier\n",
    "\n",
    "print(elo_k(-1, elo1_pre - elo2_pre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_something = pickle.load(open('2019_data_june23.pickle', 'rb'))\n",
    "loaded_something.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "game_log_df = pd.read_csv(\"./game_logs_00_20.csv\")\n",
    "game_log_df['date']= pd.to_datetime(game_log_df['date'])\n",
    "game_log_df['h_team'] = game_log_df['h_team'].astype(str)\n",
    "game_log_df['a_team'] = game_log_df['a_team'].astype(str)\n",
    "\n",
    "# Handle alternate team abbreviation\n",
    "game_log_df[\"h_team\"].replace({\"NYN\": \"NYM\", \"CHN\": \"CHC\", \"FLO\": \"FLA\", \"MON\": \"WSN\", \"SLN\": \"STL\", \"KCA\": \"KCR\", \"TBA\": \"TBD\", \"SDN\": \"SDP\", \"NYA\": \"NYY\", \"LAN\": \"LAD\", \"WAS\": \"WSN\", \"MIA\": \"FLA\", \"CHA\": \"CHW\", \"SFN\": \"SFG\", \"nan\": float(\"NaN\")}, inplace=True)\n",
    "\n",
    "game_log_df.dropna(subset=[\"a_team\", \"h_team\"], inplace=True)\n",
    "\n",
    "game_log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.merge(game_log_df, elo_df,  how='left', left_on=['date','a_team', 'h_team'], right_on = ['date','team2', 'team1'])\n",
    "new_df.dropna(subset=[\"a_team\", \"h_team\", \"team1\", \"team2\"], inplace=True)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(new_df.iloc[:, 77:161], inplace=True, axis=1)\n",
    "new_df = new_df.drop(['game_num', 'day_of_week', 'a_league', 'h_league', 'a_game_num', 'h_game_num', 'tot_oits', 'day_night', 'completion', 'forfeit', 'protest', 'park_id', 'attendance', 'tot_min', 'a_line_score', 'h_line_score', 'a_first_interference', 'h_first_interference', 'a_sac_hits', 'h_sac_hits', 'a_pitchers_used', 'h_pitchers_used', 'a_team_earned_runs', 'h_team_earned_runs', 'a_passed_balls', 'h_passed_balls', 'neutral', 'playoff'], axis=1)\n",
    "# 1 is home, 2 is away\n",
    "new_df = new_df.drop(['pitcher1', 'pitcher2', 'rating1_pre', 'rating2_pre', 'elo_prob1', 'elo_prob2', 'elo1_post', 'elo2_post', 'rating_prob1', 'rating_prob2', 'rating1_post', 'rating2_post', 'team1', 'team2', 'season', 'score1', 'score2'], axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame()\n",
    "elo_df2_builder = {\n",
    "    'h_elo': [],\n",
    "    'a_elo': [],\n",
    "    'h_pitch_rgs': [],\n",
    "    'a_pitch_rgs': [],\n",
    "    'home_win': []\n",
    "}\n",
    "\n",
    "p_bar = tqdm(total=len(new_df))\n",
    "for index, row in new_df.iterrows(): \n",
    "    h_team = row['h_team']\n",
    "    a_team = row['a_team']\n",
    "    curr_date = row['date']\n",
    "    ten_before = curr_date - datetime.timedelta(days=10)\n",
    "\n",
    "    # Home team stats\n",
    "    temp_df = new_df[new_df['date'] < curr_date]\n",
    "    temp_df = temp_df[temp_df['date'] >= ten_before]\n",
    "    temp_df.loc[(temp_df['a_team'] == h_team) | (temp_df['h_team'] == h_team) | (temp_df['a_team'] == a_team) | (temp_df['h_team'] == a_team)]\n",
    "    \n",
    "    avg_builder = {}\n",
    "    for col in new_df.columns:\n",
    "        if col.startswith('h_') or col.startswith('a_'):\n",
    "            avg_builder[col] = []\n",
    "    \n",
    "    for index2, row2 in temp_df.iterrows():\n",
    "        if row2['h_team'] == h_team:\n",
    "            for col in temp_df:\n",
    "                if col.startswith('h_'):\n",
    "                    avg_builder['h_' + col[2:]].append(row2[col])\n",
    "        elif row2['a_team'] == h_team:\n",
    "            for col in temp_df:\n",
    "                if col.startswith('a_'):\n",
    "                    avg_builder['h_' + col[2:]].append(row2[col])\n",
    "\n",
    "        if row2['h_team'] == h_team:\n",
    "            for col in temp_df:\n",
    "                if col.startswith('h_'):\n",
    "                    avg_builder['a_' + col[2:]].append(row2[col])\n",
    "        elif row2['a_team'] == h_team:\n",
    "            for col in temp_df:\n",
    "                if col.startswith('a_'):\n",
    "                    avg_builder['a_' + col[2:]].append(row2[col])\n",
    "\n",
    "    avg_df = pd.DataFrame(avg_builder)\n",
    "    avg_series = avg_df.mean()\n",
    "    \n",
    "    final_df = final_df.append(avg_series, ignore_index=True)\n",
    "    elo_df2_builder['h_elo'].append(row['elo1_pre'])\n",
    "    elo_df2_builder['a_elo'].append(row['elo2_pre'])\n",
    "    elo_df2_builder['h_pitch_rgs'].append(row['pitcher1_rgs'])\n",
    "    elo_df2_builder['a_pitch_rgs'].append(row['pitcher2_rgs'])\n",
    "    if row['h_runs'] > row['a_runs']:\n",
    "        elo_df2_builder['home_win'].append(1)\n",
    "    else:\n",
    "        elo_df2_builder['home_win'].append(0)\n",
    "\n",
    "\n",
    "    p_bar.update(1)\n",
    "\n",
    "elo_df2 = pd.DataFrame(elo_df2_builder)\n",
    "final_df = pd.concat([final_df, elo_df2], axis=1)\n",
    "final_df = final_df.drop(['h_team', 'a_team'], axis=1)\n",
    "final_df.dropna(inplace=True)\n",
    "\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv( \"training_data.csv\")"
   ]
  },
  {
   "source": [
    "**Section 2: The Model**\n",
    "\n",
    "Note that we will develop 2 models, one including a projected pitcher and the other without"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "The following model is developed for data *with* a pitcher rating included"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_pitcher = pd.read_csv(\"./training_data.csv\")\n",
    "df_with_pitcher = df_with_pitcher.loc[:, ~df_with_pitcher.columns.str.contains('^Unnamed')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   a_2_plays  a_3_plays  a_assists  a_at_bats  a_balks  a_bases_stolen  \\\n",
       "0        1.0        0.0       12.0       30.0      0.0             1.0   \n",
       "1        0.0        0.0        8.0       19.0      0.0             0.0   \n",
       "2        0.0        0.0        8.0       31.0      0.0             0.0   \n",
       "3        0.0        0.0        7.0       32.0      0.0             0.0   \n",
       "4        0.5        0.0       11.0       31.5      0.0             1.0   \n",
       "\n",
       "   a_caught_stealing  a_doubles  a_errors  a_grounded_to_double  ...  h_runs  \\\n",
       "0                0.0        0.0       0.0                   1.0  ...     2.0   \n",
       "1                0.0        1.0       2.0                   0.0  ...     3.0   \n",
       "2                0.0        0.0       2.0                   0.0  ...     4.0   \n",
       "3                0.0        1.0       1.0                   1.0  ...     6.0   \n",
       "4                0.5        1.0       0.0                   0.5  ...     2.5   \n",
       "\n",
       "   h_sac_flies  h_strikeouts  h_triples  h_walks  h_wild_pitches     h_elo  \\\n",
       "0          0.0           6.0        0.0      1.0             0.0  1553.796   \n",
       "1          0.0           4.0        0.0      1.0             0.0  1535.065   \n",
       "2          0.0           9.0        0.0      3.0             0.0  1507.673   \n",
       "3          0.0           3.0        0.0      0.0             0.0  1543.445   \n",
       "4          0.0           5.0        0.0      2.5             0.0  1551.499   \n",
       "\n",
       "      a_elo  h_pitch_rgs  a_pitch_rgs  \n",
       "0  1481.365       54.127       50.678  \n",
       "1  1483.306       54.683       47.400  \n",
       "2  1477.837       53.279       46.325  \n",
       "3  1485.881       52.733       45.771  \n",
       "4  1483.662       61.106       48.920  \n",
       "\n",
       "[5 rows x 52 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>a_2_plays</th>\n      <th>a_3_plays</th>\n      <th>a_assists</th>\n      <th>a_at_bats</th>\n      <th>a_balks</th>\n      <th>a_bases_stolen</th>\n      <th>a_caught_stealing</th>\n      <th>a_doubles</th>\n      <th>a_errors</th>\n      <th>a_grounded_to_double</th>\n      <th>...</th>\n      <th>h_runs</th>\n      <th>h_sac_flies</th>\n      <th>h_strikeouts</th>\n      <th>h_triples</th>\n      <th>h_walks</th>\n      <th>h_wild_pitches</th>\n      <th>h_elo</th>\n      <th>a_elo</th>\n      <th>h_pitch_rgs</th>\n      <th>a_pitch_rgs</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>12.0</td>\n      <td>30.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1553.796</td>\n      <td>1481.365</td>\n      <td>54.127</td>\n      <td>50.678</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>19.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1535.065</td>\n      <td>1483.306</td>\n      <td>54.683</td>\n      <td>47.400</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>31.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>9.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1507.673</td>\n      <td>1477.837</td>\n      <td>53.279</td>\n      <td>46.325</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>7.0</td>\n      <td>32.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1543.445</td>\n      <td>1485.881</td>\n      <td>52.733</td>\n      <td>45.771</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.5</td>\n      <td>0.0</td>\n      <td>11.0</td>\n      <td>31.5</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.5</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.5</td>\n      <td>...</td>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>2.5</td>\n      <td>0.0</td>\n      <td>1551.499</td>\n      <td>1483.662</td>\n      <td>61.106</td>\n      <td>48.920</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 52 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "y = df_with_pitcher['home_win']\n",
    "df_with_pitcher.drop(columns=['home_win'], inplace=True)\n",
    "X = df_with_pitcher\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X.head()"
   ]
  },
  {
   "source": [
    "XGBoost"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "# data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "xg_clf = xgb.XGBClassifier(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xg_clf, param_distributions = parameters, scoring = \"f1_micro\",\n",
    "                             cv = 10, verbose = 3, random_state = 40 )\n",
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(model_xgboost.best_estimator_._Booster)\n",
    "plt.figure(figsize = (16, 12))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_probs = model_xgboost.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_xgboost.predict(X_test)\n",
    "mse = mean_squared_error(y_test_pred, y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_xgboost, open('../../hoth/mlb_pregame_prediction_with_pitcher.pkl', 'wb'))"
   ]
  },
  {
   "source": [
    "Now we use the same model without the pitcher game score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_without_pitcher = pd.read_csv(\"./training_data.csv\")\n",
    "df_without_pitcher = df_without_pitcher.loc[:, ~df_without_pitcher.columns.str.contains('^Unnamed')]\n",
    "df_without_pitcher.drop(columns=['h_pitch_rgs', 'a_pitch_rgs'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_without_pitcher['home_win']\n",
    "df_without_pitcher.drop(columns=['home_win'], inplace=True)\n",
    "X = df_without_pitcher\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "parameters = {\"learning_rate\": [0.1, 0.01, 0.001],\n",
    "               \"gamma\" : [0.01, 0.1, 0.3, 0.5, 1, 1.5, 2],\n",
    "               \"max_depth\": [2, 4, 7, 10],\n",
    "               \"colsample_bytree\": [0.3, 0.6, 0.8, 1.0],\n",
    "               \"subsample\": [0.2, 0.4, 0.5, 0.6, 0.7],\n",
    "               \"reg_alpha\": [0, 0.5, 1],\n",
    "               \"reg_lambda\": [1, 1.5, 2, 3, 4.5],\n",
    "               \"min_child_weight\": [1, 3, 5, 7],\n",
    "               \"n_estimators\": [100, 250, 500, 1000]}\n",
    "\n",
    "# data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "xg_clf = xgb.XGBClassifier(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)\n",
    "\n",
    "xgb_rscv = RandomizedSearchCV(xg_clf, param_distributions = parameters, scoring = \"f1_micro\",\n",
    "                             cv = 10, verbose = 3, random_state = 40 )\n",
    "model_xgboost = xgb_rscv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_xgboost.predict(X_test)\n",
    "mse = mean_squared_error(y_test_pred, y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_xgboost, open('../../hoth/mlb_pregame_prediction_without_pitcher.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}